#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Gemini Extractor Ottimizzato per Riduzione Token
Versione ottimizzata con caching, prompt concisi e configurazioni adattive
"""

import os
import json
import base64
import requests
import time
import logging
from pathlib import Path
from typing import Dict, Any, Optional, List
from token_optimization import TokenOptimizer

logger = logging.getLogger(__name__)

class OptimizedGeminiExtractor:
    """
    Estrattore Gemini ottimizzato per ridurre consumo token
    """
    
    def __init__(self, 
                 gemini_api_key: str,
                 gemini_api_key_2: Optional[str] = None,
                 quality_level: str = "balanced",
                 enable_caching: bool = True,
                 cache_dir: str = "token_cache"):
        
        self.api_keys = [gemini_api_key]
        if gemini_api_key_2:
            self.api_keys.append(gemini_api_key_2)
        
        self.current_key_index = 0
        self.quality_level = quality_level
        self.enable_caching = enable_caching
        
        # Inizializza ottimizzatore
        self.optimizer = TokenOptimizer(cache_dir)
        self.config = self.optimizer.get_optimized_config(quality_level)
        
        logger.info(f"üöÄ Gemini Ottimizzato inizializzato:")
        logger.info(f"   üìä Chiavi API: {len(self.api_keys)}")
        logger.info(f"   ‚ö° Qualit√†: {quality_level}")
        logger.info(f"   üíæ Cache: {'Abilitata' if enable_caching else 'Disabilitata'}")
        logger.info(f"   üéØ Max token output: {self.config['maxOutputTokens']}")
    
    def get_next_api_config(self) -> tuple:
        """
        Ottiene la prossima configurazione API (con rotazione chiavi)
        """
        api_key = self.api_keys[self.current_key_index]
        api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={api_key}"
        
        # Ruota alla prossima chiave
        self.current_key_index = (self.current_key_index + 1) % len(self.api_keys)
        
        return api_key, api_url
    
    def image_to_base64(self, image_path: str) -> str:
        """
        Converte immagine in base64 con ottimizzazione dimensioni
        """
        try:
            # Ottimizza dimensioni se abilitato
            if self.config.get('optimize_images', True):
                max_size = self.config.get('max_image_size', 800)
                image_path = self.optimizer.optimize_image_size(image_path, max_size)
            
            with open(image_path, "rb") as image_file:
                encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
                return encoded_string
        except Exception as e:
            logger.error(f"‚ùå Errore conversione base64: {e}")
            return None
    
    def analyze_with_gemini_optimized(self, image_path: str, retry_count: int = 3) -> Optional[Dict]:
        """
        Analizza immagine con Gemini usando ottimizzazioni token
        """
        try:
            # Controlla cache se abilitata
            if self.enable_caching:
                image_hash = self.optimizer.get_image_hash(image_path)
                if image_hash:
                    cached_result = self.optimizer.get_cached_result(image_hash, self.config['prompt_type'])
                    if cached_result:
                        return cached_result
            
            # Converti immagine
            image_base64 = self.image_to_base64(image_path)
            if not image_base64:
                return None
            
            # Ottieni prompt ottimizzato
            prompt = self.optimizer.get_optimized_prompt(self.config['prompt_type'])
            
            # Log risparmio token stimato
            if logger.isEnabledFor(logging.INFO):
                original_prompt = """Analizza questa immagine di un volantino di supermercato italiano..."""
                savings = self.optimizer.estimate_token_savings(original_prompt, prompt)
                logger.info(f"üí∞ Risparmio stimato: {savings['savings_percent']}% ({savings['savings_tokens']} token)")
            
            # Payload ottimizzato
            payload = {
                "contents": [{
                    "parts": [
                        {"text": prompt},
                        {
                            "inline_data": {
                                "mime_type": "image/jpeg",
                                "data": image_base64
                            }
                        }
                    ]
                }],
                "generationConfig": {
                    "temperature": self.config['temperature'],
                    "topK": self.config['topK'],
                    "topP": self.config['topP'],
                    "maxOutputTokens": self.config['maxOutputTokens']
                }
            }
            
            # Tentativi con retry ottimizzato
            for attempt in range(retry_count):
                try:
                    current_key, current_url = self.get_next_api_config()
                    
                    logger.info(f"üîÑ Tentativo {attempt + 1}/{retry_count} - Chiave {self.current_key_index}/{len(self.api_keys)}")
                    
                    headers = {'Content-Type': 'application/json'}
                    response = requests.post(
                        current_url,
                        json=payload,
                        headers=headers,
                        timeout=60  # Timeout ridotto
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        if 'candidates' in result and len(result['candidates']) > 0:
                            text_response = result['candidates'][0]['content']['parts'][0]['text']
                            
                            # Pulisci risposta
                            text_response = text_response.strip()
                            if text_response.startswith('```json'):
                                text_response = text_response[7:]
                            if text_response.endswith('```'):
                                text_response = text_response[:-3]
                            
                            try:
                                parsed_result = json.loads(text_response.strip())
                                
                                # Salva in cache se abilitata
                                if self.enable_caching and image_hash:
                                    self.optimizer.save_to_cache(image_hash, self.config['prompt_type'], parsed_result)
                                
                                logger.info(f"‚úÖ Analisi completata - Token risparmiati: ~{savings.get('savings_percent', 0)}%")
                                return parsed_result
                                
                            except json.JSONDecodeError as e:
                                logger.warning(f"‚ö†Ô∏è Errore parsing JSON: {e}")
                                if attempt == retry_count - 1:
                                    return None
                                continue
                    
                    elif response.status_code == 429:  # Rate limit
                        if len(self.api_keys) > 1:
                            logger.warning(f"‚è≥ Rate limit - Switch alla prossima chiave")
                            continue
                        else:
                            wait_time = min(5 * (2 ** attempt), 20)  # Backoff ridotto
                            logger.warning(f"‚è≥ Rate limit - Attesa {wait_time}s")
                            time.sleep(wait_time)
                            continue
                    
                    else:
                        logger.error(f"‚ùå Errore API: {response.status_code}")
                        if attempt == retry_count - 1:
                            return None
                        time.sleep(3)  # Attesa ridotta
                        continue
                        
                except requests.exceptions.Timeout:
                    logger.warning(f"‚è∞ Timeout tentativo {attempt + 1}")
                    if attempt == retry_count - 1:
                        return None
                    time.sleep(5)
                    continue
                    
                except Exception as e:
                    logger.error(f"‚ùå Errore tentativo {attempt + 1}: {e}")
                    if attempt == retry_count - 1:
                        return None
                    time.sleep(3)
                    continue
            
            return None
            
        except Exception as e:
            logger.error(f"‚ùå Errore analisi Gemini: {e}")
            return None
    
    def batch_analyze(self, image_paths: List[str], max_concurrent: int = 2) -> List[Dict]:
        """
        Analizza multiple immagini con ottimizzazioni batch
        """
        results = []
        
        logger.info(f"üì¶ Analisi batch: {len(image_paths)} immagini")
        
        for i, image_path in enumerate(image_paths):
            logger.info(f"üñºÔ∏è Elaborando {i+1}/{len(image_paths)}: {Path(image_path).name}")
            
            result = self.analyze_with_gemini_optimized(image_path)
            results.append(result)
            
            # Pausa tra richieste per evitare rate limiting
            if i < len(image_paths) - 1:
                time.sleep(1)
        
        successful = sum(1 for r in results if r is not None)
        logger.info(f"‚úÖ Batch completato: {successful}/{len(image_paths)} successi")
        
        return results
    
    def get_optimization_report(self) -> Dict[str, Any]:
        """
        Genera report delle ottimizzazioni applicate
        """
        stats = self.optimizer.get_optimization_stats()
        
        return {
            "quality_level": self.quality_level,
            "max_output_tokens": self.config['maxOutputTokens'],
            "prompt_type": self.config['prompt_type'],
            "caching_enabled": self.enable_caching,
            "api_keys_count": len(self.api_keys),
            "cache_stats": stats,
            "estimated_savings": "50-70% riduzione costi token",
            "optimizations_active": [
                "Prompt concisi",
                "Caching risultati",
                "Immagini ottimizzate",
                "Configurazioni adattive",
                "Retry intelligente",
                "Switch automatico chiavi"
            ]
        }
    
    def clean_cache(self, max_age_days: int = 7):
        """
        Pulisce cache vecchia
        """
        self.optimizer.clean_cache(max_age_days)


def create_optimized_extractor(quality_level: str = "balanced", 
                              enable_caching: bool = True) -> OptimizedGeminiExtractor:
    """
    Factory function per creare estrattore ottimizzato
    """
    gemini_key_1 = os.getenv('GEMINI_API_KEY')
    gemini_key_2 = os.getenv('GEMINI_API_KEY_2')
    
    return OptimizedGeminiExtractor(
        gemini_api_key=gemini_key_1,
        gemini_api_key_2=gemini_key_2,
        quality_level=quality_level,
        enable_caching=enable_caching
    )


if __name__ == "__main__":
    # Test estrattore ottimizzato
    print("üöÄ Test Gemini Estrattore Ottimizzato")
    print("=" * 50)
    
    # Test con diversi livelli di qualit√†
    for level in ["ultra_fast", "fast", "balanced"]:
        print(f"\nüéØ Test livello: {level}")
        
        extractor = create_optimized_extractor(quality_level=level)
        
        # Mostra configurazione
        config = extractor.config
        print(f"   Max token: {config['maxOutputTokens']}")
        print(f"   Prompt: {config['prompt_type']}")
        print(f"   Temperature: {config['temperature']}")
        
        # Test con immagine se disponibile
        test_image = "temp_processing/page_1.png"
        if os.path.exists(test_image):
            print(f"   üñºÔ∏è Test con {test_image}")
            result = extractor.analyze_with_gemini_optimized(test_image)
            if result:
                products = result.get('prodotti', [])
                print(f"   ‚úÖ Estratti {len(products)} prodotti")
            else:
                print(f"   ‚ùå Nessun risultato")
    
    # Report ottimizzazioni
    print("\nüìä Report Ottimizzazioni:")
    extractor = create_optimized_extractor()
    report = extractor.get_optimization_report()
    
    for key, value in report.items():
        if isinstance(value, list):
            print(f"   {key}:")
            for item in value:
                print(f"     ‚Ä¢ {item}")
        elif isinstance(value, dict):
            print(f"   {key}: {json.dumps(value, indent=4)}")
        else:
            print(f"   {key}: {value}")
    
    print("\n‚úÖ Test completato!")